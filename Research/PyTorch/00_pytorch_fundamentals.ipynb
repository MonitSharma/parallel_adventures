{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BXq1h1EpPkW",
        "outputId": "7abf68c9-3352-4f66-e666-19a0d46f96f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "%pip install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmbgmYRipgs6",
        "outputId": "41c22742-8ef3-49d0-9dc8-e1156bc33d9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Jul 10 19:06:30 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 565.57.01              Driver Version: 566.24         CUDA Version: 12.7     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3070        On  |   00000000:01:00.0  On |                  N/A |\n",
            "| 30%   48C    P8             20W /  220W |    7836MiB /   8192MiB |      6%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A       499      G   /Xwayland                                   N/A      |\n",
            "|    0   N/A  N/A      4897      C   /python3.11                                 N/A      |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YemCSz3upaEg"
      },
      "source": [
        "Let's check the `PyTorch` version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pjB9BRL1pZDS",
        "outputId": "ac75cc25-70c9-4627-e55d-f299b4f77b4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.7.1+cu126'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQHe2U8TpjmE"
      },
      "source": [
        "All this work will be compatible with the above mentioned version of PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WybH3R16po7q"
      },
      "source": [
        "## **Tensors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYz5WjHYprB8"
      },
      "source": [
        "Tensors are fundamental for machine learning. They represent data in numerical way. We can represent a tensor with shape `[3,224,224]` which would mean `[colour_channels, height, width]`\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ9q6lCHp9_i"
      },
      "source": [
        "### **Creating Tensors**\n",
        "\n",
        "PyTorch has a whole documentation for the `torch.Tensor` class. Let's go through it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEKsB9guqJyp"
      },
      "source": [
        "A `torch.Tensor` is a multi-dimensional matrix containing elements of a single data type.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brIviEFPpfAD",
        "outputId": "6b4c9a03-7fbd-42df-fc0d-4e6148ea3026"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1, -1],\n",
              "        [-1,  1]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.tensor([[1,-1],[-1,1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ2L7ei6qk88",
        "outputId": "c3404012-caba-4726-99ac-34e9c6abe577"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "torch.tensor(np.array([[1,2,3],[4,5,6]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvwpZZgsq2Yd"
      },
      "source": [
        "#### **Scalar**\n",
        "\n",
        "Let's start with scalar, a scalar is a single number and in tensor language it is a zero dimensional tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJPitX1Uqp9T",
        "outputId": "a2923a11-ca8b-45d8-b1e4-3d83ab04b677"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scalar = torch.tensor(9)\n",
        "scalar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHbr1iPvrCFa"
      },
      "source": [
        "It measn, that although the `scalar` is a number, its type is `torch.Tensor`. We can check the dimensions of the tensor using `ndim`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QeTtKoMrAly",
        "outputId": "1f2e9f7e-1837-4c10-b0b4-da67e6602d1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scalar.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whG2FZTTrQ07"
      },
      "source": [
        "and if we want to extract the number out of the tensor, we can convert it to a Python integer, using `item()` method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JODRg_-yrOJT",
        "outputId": "6d708a30-1c21-4317-c7fe-be5469e1b022"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scalar.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fypQA0mXreU0"
      },
      "source": [
        "#### **Vector**\n",
        "\n",
        "A vector is a single dimensional tensor, and can contain many numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCP3Xrb_rZpx",
        "outputId": "83ed1c4f-7844-48b8-dd8a-ba22b4421574"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector = torch.tensor([7,7])\n",
        "vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naEUwOcJrq0y",
        "outputId": "799c8cd9-5dd8-46b6-d444-44d55db88767"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEO90vsLruhk"
      },
      "source": [
        "You can tell the dimension of the tensor, by how many number of square brackets `[` are on the outside, and you only need to count on the one side. Here it's only one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkNt5uF5rsyS",
        "outputId": "7a5654ba-d704-4bc4-d444-66968eaa1eb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_Qdqaz5r8Ry"
      },
      "source": [
        "Since it has two elements, it's shape is 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAJTArXQsALb"
      },
      "source": [
        "#### **Matrix**\n",
        "\n",
        "I don't think it needs any definition, everyone knows a matrix, well everyone knew a vector too, but it's nice to reiterate the basic building block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlvEusB2r61U",
        "outputId": "8cb98321-6eaa-4453-c546-25480b3027e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX = torch.tensor([[7,8],[9,10]])\n",
        "MATRIX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euxMIGJgsTUz"
      },
      "source": [
        "There's a reason I wrote `MATRIX` in all caps, instead of `matrix`, since `matrix` is used very frequently in code. Now guess it's dimensions?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffluYywMsSZi",
        "outputId": "642a0949-8919-4c88-d167-0673e436a91c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOsna4G9shXU"
      },
      "source": [
        "and the shape?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6iJfbxJsfqi",
        "outputId": "6e29c9c7-5ee6-474b-ba74-0f215dee077f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i9jUSIgskCq"
      },
      "source": [
        "Since it's a $2\\times2$ matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q4Ttuynsopr"
      },
      "source": [
        "#### **Tensor**\n",
        "\n",
        "Well tensor is a tensor. It is something that transforms like a tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUULodkIsjlR",
        "outputId": "d0b19484-a6e1-4bdd-9422-028bb8024766"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [4, 5, 6],\n",
              "         [7, 8, 9]]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TENSOR = torch.tensor([[[1,2,3],[4,5,6], [7,8,9]]])\n",
        "TENSOR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zLOiaNEs25a"
      },
      "source": [
        "Same reason for using a `TENSOR` here instead of `tensor`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqXvgYzAs2by",
        "outputId": "26b59384-84f0-44bd-d5d2-aa961aa2b1f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TENSOR.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXyrr5VZs_Vz",
        "outputId": "f5173fba-aa76-496b-930a-0a432ba1e77f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TENSOR.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tV7w_zTtEP6"
      },
      "source": [
        "We can make a $3 \\times 3 \\times 3$ tensor as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfr5xGi8tBmS",
        "outputId": "69138a23-84a8-4d13-84cc-364833819cb6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [4, 5, 6],\n",
              "         [7, 8, 9]],\n",
              "\n",
              "        [[1, 2, 3],\n",
              "         [4, 5, 6],\n",
              "         [7, 8, 9]],\n",
              "\n",
              "        [[1, 2, 3],\n",
              "         [4, 5, 6],\n",
              "         [7, 8, 9]]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TENSOR = torch.tensor([[[1,2,3],[4,5,6], [7,8,9]],[[1,2,3],[4,5,6], [7,8,9]],[[1,2,3],[4,5,6], [7,8,9]]])\n",
        "TENSOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HygplEdgtK2T",
        "outputId": "ec007eba-304c-4bbf-fd0d-5f2b7d7394e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 3, 3])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TENSOR.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2oy2-JjtMeS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWBYkaRetdZT"
      },
      "source": [
        "### **Random Tensors**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU37VywqtiUj"
      },
      "source": [
        "In machine learning models, we manipulate these tensors and try to seek pattern among them. Let's see how can we create random tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWi9V5uathwh",
        "outputId": "c0753ee6-b4cb-4ed5-d74d-d11047b42f7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2485, 0.7105, 0.3127, 0.8816],\n",
            "        [0.6174, 0.0922, 0.5848, 0.3300],\n",
            "        [0.2171, 0.8162, 0.8548, 0.6319]])\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n"
          ]
        }
      ],
      "source": [
        "random_tensor = torch.rand(size=(3, 4))\n",
        "print(random_tensor)\n",
        "print(f\"Shape of tensor: {random_tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {random_tensor.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dscYg_JKt12r"
      },
      "source": [
        "We can adjust it to any shape or size that we want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdeuFTwjtyeS",
        "outputId": "e68dbdf7-d324-42ac-ac69-504bbbcd438f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_image_size_tensor = torch.rand(size=(224,224,3))\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTZx9CH_uDeT"
      },
      "source": [
        "I will not print it, since it is very big, but you get the idea."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC0ISSlSuIWE"
      },
      "source": [
        "### **Zeros and Ones**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwFl2m2HuKbV"
      },
      "source": [
        "Sometimes we need to do padding, i.e we need to fill tensors with zeros and ones, like for Identity matrix or zero matrix, we can make them easily."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCSAT8BluCDj",
        "outputId": "0667a423-ca3e-4d7a-fb97-e2d9a77122dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n"
          ]
        }
      ],
      "source": [
        "zeros = torch.zeros(size=(3,4))\n",
        "print(zeros)\n",
        "print(f\"Shape of tensor: {zeros.shape}\")\n",
        "print(f\"Datatype of tensor: {zeros.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD_AbhY5ubjr"
      },
      "source": [
        "can do the same for ones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Czy_ufx9uZ_j",
        "outputId": "42242fc6-d400-419b-cd77-f2e1155f4ddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n"
          ]
        }
      ],
      "source": [
        "ones = torch.ones(size=(3,4))\n",
        "print(ones)\n",
        "print(f\"Shape of tensor: {ones.shape}\")\n",
        "print(f\"Datatype of tensor: {ones.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZL3o5VBuhLC"
      },
      "source": [
        "### **Range in Tensors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhSFYKaSujoy"
      },
      "source": [
        "Sometimes we want a range of numbers, like 1-10 or even 100, we can make use of `torch.arange(start, end,step)` and to do so:\n",
        "\n",
        "- `start` = start of the range\n",
        "- `end` = end of the range\n",
        "- `step` = how many steps to take between each value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z-ByDssufCS",
        "outputId": "5d27dad3-821d-4b43-be77-c6880dae3a58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
        "zero_to_ten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjoyuNm1u-HS"
      },
      "source": [
        "suppose you want a tensor of all zeros, but of the same shape as the other tensor, easier way to do this is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBdSpe6pu8hy",
        "outputId": "115d0390-50be-4b62-d635-5815ee4a7e6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ten_zeros = torch.zeros_like(input=zero_to_ten)\n",
        "ten_zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jrxs5AwvHt0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiYjx3_HvYAs"
      },
      "source": [
        "### **Tensor Datatypes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGpQ-dsHvati"
      },
      "source": [
        "There are many different datatypes available in PyTorch, some are CPU specific, some are GPU specific. General rule of thumb is, if you see `cuda` written anywhere, its being used for GPU.\n",
        "\n",
        "The default are `torch.float32` or `torch.float`, this refers to the 32-bit floating point, but thre are 16-bit and 64-bit floating point as well.\n",
        "\n",
        "\n",
        "They are here to do precision in computing, i.e the amount of details we are using to describe a number, lower precision datatypes are generally faster to compute, but sacrifice some performance on evaluation metrics, like accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWkYiURevaPS",
        "outputId": "22671dac-8365-41d6-8c9b-b061cd90645b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([3., 6., 9.])\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
        "                               device=None, # defaults to None, which uses the default tensor\n",
        "                               requires_grad=False) # if True, operations perfromed on the tensor are recorded\n",
        "\n",
        "print(float_32_tensor)\n",
        "print(float_32_tensor.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLFJMILa3aTz",
        "outputId": "f8c4ef00-d2d3-43d1-d361-99e942809230"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=torch.float16) # torch.half would also work\n",
        "\n",
        "float_16_tensor.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN2iw-Z33kca"
      },
      "source": [
        "The broad idea is to keep the tensor of the same precision and on the same device."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4ApRfz23xXM"
      },
      "source": [
        "#### **Getting Information**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kbw7PVAq3zkm"
      },
      "source": [
        "We can get information out of tensor as well, so you can debugg if you face any error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMoC3Hiq3jjD",
        "outputId": "f0f16b77-5d67-4da1-dda9-b6e9a19b5068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.6146, 0.0921, 0.5154, 0.0826],\n",
            "        [0.9760, 0.8325, 0.9739, 0.7954],\n",
            "        [0.3148, 0.6308, 0.4066, 0.1792]])\n",
            "Datatype of tensor: torch.float32\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ],
      "source": [
        "some_tensor = torch.rand(3,4)\n",
        "\n",
        "print(some_tensor)\n",
        "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
        "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
        "print(f\"Device tensor is stored on: {some_tensor.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mi0AeaGd384k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuk2ITtnBOxt"
      },
      "source": [
        "### **Manipulating Tensors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs3cCDNRBVwU"
      },
      "source": [
        "In deep learning, data (images, texts, videos, audios) get represeneted as tensors. A model learns by investigating those tensors and performing a series of operations on tensors to create a representation of the pattern in the input data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwYspne3BSBi",
        "outputId": "12b90e00-6b30-4f45-d6a8-0d912cad94fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([10, 10, 10])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# addition\n",
        "t1 = torch.tensor([1,2,3])\n",
        "t2 = torch.tensor([9,8,7])\n",
        "t1 + t2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7sw0_bFDNOW",
        "outputId": "f09aa6e0-1951-48b1-9542-5c0ebf304464"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t1+10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76KD6R7bDPMy",
        "outputId": "77ed0512-e044-43d7-d120-92c5b5d5b68a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# multiply by 10\n",
        "t1*10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf-o9QpwDTgj",
        "outputId": "c59fcd9d-7889-4c44-f52d-da70af3954d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# subtract\n",
        "t1-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LfU_bClDdME"
      },
      "source": [
        "PyTorch has some inbuilt functions as well, like `torch.mul()` and `torch.add()` to perform basic operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv1o83b6DcCD",
        "outputId": "26720196-3786-4fdf-d7ae-b2f7d6f77369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.multiply(t1,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXRod945DrNz"
      },
      "source": [
        "#### **Matrix Multiplication**\n",
        "\n",
        "This is the one most used, the most common one, in pytorch it is implemented by `torch.matmul()`\n",
        "\n",
        "and you know the basic rules of matrix multiplication, they will work here as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J2oA5yMDopy",
        "outputId": "bb77af7d-1fd9-4602-dd20-61dd2a7ab034"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Element-wise multiplication:\n",
            "tensor([[ 7, 20],\n",
            "        [24, 44],\n",
            "        [45, 72]])\n",
            "\n",
            "Matrix multiplication (A @ B.T):\n",
            "tensor([[ 27,  30,  33],\n",
            "        [ 61,  68,  75],\n",
            "        [ 95, 106, 117]])\n",
            "\n",
            "Matrix multiplication (A @ B.T) using @ operator:\n",
            "tensor([[ 27,  30,  33],\n",
            "        [ 61,  68,  75],\n",
            "        [ 95, 106, 117]])\n"
          ]
        }
      ],
      "source": [
        "# multiply two tensors\n",
        "\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]])\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]])\n",
        "\n",
        "# Element-wise multiplication\n",
        "element_wise_multiply = tensor_A * tensor_B\n",
        "print(f\"Element-wise multiplication:\\n{element_wise_multiply}\")\n",
        "\n",
        "# Matrix multiplication (requires appropriate shapes, transpose one if needed)\n",
        "# For A (3x2) and B (3x2), we can't do A @ B. We can do A @ B.T (3x2 @ 2x3 -> 3x3)\n",
        "matrix_multiply = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(f\"\\nMatrix multiplication (A @ B.T):\\n{matrix_multiply}\")\n",
        "\n",
        "# Alternative using the @ operator\n",
        "matrix_multiply_alt = tensor_A @ tensor_B.T\n",
        "print(f\"\\nMatrix multiplication (A @ B.T) using @ operator:\\n{matrix_multiply_alt}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ-8HZHyEOo3"
      },
      "source": [
        "Let's see which method is faster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOaSdEiuFD6V",
        "outputId": "1080f687-52ea-4cbc-e37d-448b29de78d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_1 = torch.tensor([1,2,3])\n",
        "tensor_1 * tensor_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zamCG8EuEhkD",
        "outputId": "fa47ad27-e5d3-41f6-c75b-c4dabc982a16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1.52 ms, sys: 184 μs, total: 1.71 ms\n",
            "Wall time: 1.2 ms\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "value = 0\n",
        "for i in range(len(tensor_1)):\n",
        "  value += tensor_1[i] * tensor_1[i]\n",
        "value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FA0lks1WFATD",
        "outputId": "cd7c75b6-0742-4719-bdea-3816e0dd0c94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 0 ns, sys: 1.19 ms, total: 1.19 ms\n",
            "Wall time: 1.62 ms\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "torch.matmul(tensor_1, tensor_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0i0d3qBFlMd"
      },
      "source": [
        "### **ERRORS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIoqtYxuFnO8"
      },
      "source": [
        "The most common errors you will encounter are the shape errors, since most of the deep learning is multiplying and performing operations on matrices, and they have a strict rule on what shapes and sizes can be combined, so beware of that"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty08knKlGBfm"
      },
      "source": [
        "Neural networks are full of matrix multiplication and dot products, the `torch.nn.Linear()`  module, also known as the feed forward layer of fully connected later, implements a matrix multiplication between input `x` and a weight matrix `A`\n",
        "\n",
        "$$ y = x \\cdot A^{T} + b $$\n",
        "\n",
        "\n",
        "where :    \n",
        "\n",
        "- `x` is the input to the layer\n",
        "- `A` is the weight matrix created by the layer, this starts as random numbers that gets adjusted as the neural network learns to better represent the patterns in the data\n",
        "\n",
        "- `b` is the bias term used to slightly offset the weights and inputs\n",
        "- `y` is the output\n",
        "\n",
        "\n",
        "This is a linear function, and can be used to draw a straight line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "IBwgNxY5HGev"
      },
      "outputs": [],
      "source": [
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbl25kh0FZIy",
        "outputId": "2d47f936-aaab-44e1-e984-3f696e247fe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([3, 2])\n",
            "\n",
            "Output:\n",
            "tensor([[ 0.1249, -0.2955,  0.3669, -0.5446, -1.7832,  0.1389,  0.9449,  1.1352],\n",
            "        [ 0.1128,  0.0201,  1.3077, -1.8505, -2.7124,  0.4187,  1.7903,  1.8160],\n",
            "        [ 0.1006,  0.3357,  2.2486, -3.1563, -3.6416,  0.6986,  2.6357,  2.4968]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Output shape: torch.Size([3, 8])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(2)\n",
        "\n",
        "linear = torch.nn.Linear(in_features=2, out_features=8)\n",
        "x = tensor_A\n",
        "output = linear(x)\n",
        "print(f\"Input shape: {x.shape}\\n\")\n",
        "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCjGYOyUIL0t"
      },
      "source": [
        "#### **Min, MAX, Mean, SUM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8whzsn8xG9OV",
        "outputId": "db54e637-37de-4e72-b0e6-dd59a8004fc2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_1 = torch.arange(0,100,10)\n",
        "tensor_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0jXFrE9IT4i",
        "outputId": "e14d5c4c-eb50-4a7f-b3a2-e149b2839ad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minimum: 0\n",
            "Maximum: 90\n",
            "Mean: 45.0\n",
            "Sum: 450\n"
          ]
        }
      ],
      "source": [
        "# performing aggregation\n",
        "print(f\"Minimum: {tensor_1.min()}\")\n",
        "print(f\"Maximum: {tensor_1.max()}\")\n",
        "# print(f\"Mean: {tensor_1.mean()}\") # this will error , to take an average, you have to define the datatype\n",
        "print(f\"Mean: {tensor_1.type(torch.float32).mean()}\") # won't work without float datatype\n",
        "print(f\"Sum: {tensor_1.sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3KCaR07Il7T"
      },
      "source": [
        "#### **Positional Min Max**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEAfwK1pIo10"
      },
      "source": [
        "We can also find the index of the tensor where the maximum or the minimum occurs, using `torch.argmax()` and `torch.argmin()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlJ4X7CRIY3j",
        "outputId": "1d7358f3-acac-4201-f20b-e83ef523769b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index where maximum value occurs is 9\n",
            "Index where minimum value occurs is 0\n"
          ]
        }
      ],
      "source": [
        "print(f\"Index where maximum value occurs is {tensor_1.argmax()}\")\n",
        "print(f\"Index where minimum value occurs is {tensor_1.argmin()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5DZkzG3JDDm"
      },
      "source": [
        "### **Change Tensor Datatype**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD9Z0_2RJFnT"
      },
      "source": [
        "If one tensor is in `torch.float16` and the other in `torch.float64`, we will run into errors, but we can change the datatypes and fix it, using `torch.Tensor.dtype(dtype=None)`, let's see an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8LHUynoI3Y0",
        "outputId": "7a9de23c-c23d-46b9-a2de-3713558237b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_1.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzALJSb3JXN0",
        "outputId": "019afff9-1260-43f1-d1db-a7eb3773d611"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_float_16 = tensor_1.type(torch.float16)\n",
        "tensor_float_16.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhbiNx9gJoLj",
        "outputId": "7132d464-ef40-404f-9f6b-96ca18ac9c50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0., 10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_float_16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwBTvd-fJwtM"
      },
      "source": [
        "Different datatypes , with different numbers might be confusing, but think it like this way, smaller the number, the less precise the computer stores the value and faster the calculation is, but it is less precise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNflbfmTJ931"
      },
      "source": [
        "### **Reshaping, stacking, squeezing and unsqueezing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNaRWUI2QpO9"
      },
      "source": [
        "Some times, we want to reshapr, or change the dimensions of the tensors we are working with, without changing anything, so we make use of the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSe47NkfJqR5",
        "outputId": "2e9d3a33-22b7-4cb3-cdc4-d0ff2a1b9ce5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor: tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "Reshaped tensor: tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]])\n"
          ]
        }
      ],
      "source": [
        "# torch.reshape(input, shape)\n",
        "\"\"\"\n",
        "Reshapes input to shape, can also use torch.Tensor.reshape()\n",
        "\"\"\"\n",
        "\n",
        "tensor_1 = torch.arange(0,100,10)\n",
        "print(f\"Original tensor: {tensor_1}\")\n",
        "\n",
        "\n",
        "# added extra dimension\n",
        "tensor_1_reshaped = tensor_1.reshape(1,10)\n",
        "print(f\"Reshaped tensor: {tensor_1_reshaped}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-urZskURM2D",
        "outputId": "6435de19-08ee-443f-cc22-5381f3c3ac1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0],\n",
              "        [10],\n",
              "        [20],\n",
              "        [30],\n",
              "        [40],\n",
              "        [50],\n",
              "        [60],\n",
              "        [70],\n",
              "        [80],\n",
              "        [90]])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# tensor.view(shape)\n",
        "\"\"\"\n",
        "Returns a view of the original tensor in a different shape but shares the same data as the original tensor.\n",
        "\"\"\"\n",
        "\n",
        "tensor_1_view = tensor_1.view(10,1)\n",
        "tensor_1_view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIT_CIfBRkT1",
        "outputId": "7cf0df4b-adca-4cbd-c760-6053cdae0b80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0],\n",
              "        [10, 10, 10],\n",
              "        [20, 20, 20],\n",
              "        [30, 30, 30],\n",
              "        [40, 40, 40],\n",
              "        [50, 50, 50],\n",
              "        [60, 60, 60],\n",
              "        [70, 70, 70],\n",
              "        [80, 80, 80],\n",
              "        [90, 90, 90]])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# torch.stack(tensors,dim=0)\n",
        "\"\"\"\n",
        "Concatenates a sequence of tensors along a new dimension (dim), all tensors must be the same size\n",
        "\"\"\"\n",
        "\n",
        "tensor_1_concat = torch.stack([tensor_1,tensor_1,tensor_1],dim=1)\n",
        "tensor_1_concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXDXuGZ-R3QU",
        "outputId": "0abff242-d999-4e5d-e4e5-cce2e5086e60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# torch.squeeze(input)\n",
        "\"\"\"\n",
        "Squeezes input by removing all the dimensions with value 1.\n",
        "\"\"\"\n",
        "\n",
        "tensor_1_squeezed = tensor_1_reshaped.squeeze()\n",
        "tensor_1_squeezed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fgEOvbRSUU0",
        "outputId": "d03c9f6f-2284-49cd-a59a-2bfaab6795a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 2, 3])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# torch.permute(input,dims)\n",
        "\"\"\"\n",
        "Returns a view of the original input with its dimensions permuted (rearranged) to dims.\n",
        "\"\"\"\n",
        "\n",
        "x = torch.randn(2, 3, 5)\n",
        "torch.permute(x, (2, 0, 1)).size()  # shift axis 0 to 1, 1 to 2 and 2 to 0\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6aOOM5wSoCd"
      },
      "source": [
        "### **Indexing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45O4nDnVSqSt"
      },
      "source": [
        "Sometimes we want to select specific data from tensors, we can use indexing for this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRdzfPVGSfcX",
        "outputId": "ee1417ec-5a17-4f4e-826a-740ecbf096e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.arange(1,10).reshape(1,3,3)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKy02eHoS4vE"
      },
      "source": [
        "Indexing goes outer dimension -> inner dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnDyH5rBS0p0",
        "outputId": "d2193b8a-6777-44a7-86c0-1f0fadc2ebea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First square bracket:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "Second square bracket: tensor([1, 2, 3])\n",
            "Third square bracket: 1\n"
          ]
        }
      ],
      "source": [
        "# Let's index bracket by bracket\n",
        "print(f\"First square bracket:\\n{x[0]}\")\n",
        "print(f\"Second square bracket: {x[0][0]}\")\n",
        "print(f\"Third square bracket: {x[0][0][0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-V0vtmvHDln"
      },
      "source": [
        "### **PyTorch tensors & NumPy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byzIBQ36HHW9"
      },
      "source": [
        "NumPy is very popular, so it is natural to have PyTorch functionally interact with it, using\n",
        "- `torch.from_numpy(ndarray)` which transform numpy array to pytorch tensor\n",
        "\n",
        "and\n",
        "\n",
        "- `torch.Tensor.numpy()` which does the opposite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAcUggiJS-_o",
        "outputId": "4d1f87e6-b3c6-4b0d-a39a-a180f9507bb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "float64\n",
            "torch.float64\n"
          ]
        }
      ],
      "source": [
        "array_1 = np.arange(1.0,8.0)\n",
        "tensor_1 = torch.from_numpy(array_1)\n",
        "print(array_1.dtype)\n",
        "print(tensor_1.dtype)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQLgFphHHdn0"
      },
      "source": [
        "Numpy arrays are by default created with `float64` and if we convert it, it is converted to the same PyTorch type. However, many PyTorch calculations are defaulted to `float32`, so keep in mind that specify the dtype\n",
        "\n",
        "`torch.from_numpy(array).type(torch.float32)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYX4SXY_H2tK",
        "outputId": "0d44b5b1-fe5b-4a0c-c92d-a7f08b4075fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "tensor_2 = torch.from_numpy(array_1).type(torch.float32)\n",
        "\n",
        "print(tensor_2.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3HlsOrHIEpS"
      },
      "source": [
        "### **Reproducibility**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBJRdJIhIG3q"
      },
      "source": [
        "We want our experiments to be reproducible, so that any other person following our code, get's the same result, and pseudorandomness plays an important role at that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb3p6MvmH_xK",
        "outputId": "9a4b4987-2a41-4af2-ef49-348256d85180"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.0445, 0.9356, 0.1712, 0.6581],\n",
            "        [0.4811, 0.5881, 0.5484, 0.0326],\n",
            "        [0.3926, 0.1839, 0.9251, 0.4386]])\n",
            "tensor([[0.0021, 0.6211, 0.7171, 0.2762],\n",
            "        [0.4531, 0.7162, 0.1889, 0.2357],\n",
            "        [0.4518, 0.1489, 0.8073, 0.5409]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ],
      "source": [
        "random_tensor_1 = torch.rand(3,4)\n",
        "random_tensor_2 = torch.rand(3,4)\n",
        "\n",
        "print(random_tensor_1)\n",
        "print(random_tensor_2)\n",
        "print(random_tensor_1 == random_tensor_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x586u26nIY7T"
      },
      "source": [
        "They are two random tensors, and they are not equal to each other at any value, but what if we want to create two random tensors with the same value. This is where `torch.manual_seed(seed)` comes in, where `seed` is an integer that flavours the randomness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GISG9O3BIXD6",
        "outputId": "66598387-76a1-4f53-b7a0-cc85d9445c31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.3002, 0.7669, 0.8898, 0.9107],\n",
            "        [0.0219, 0.6328, 0.9235, 0.2540],\n",
            "        [0.2259, 0.8689, 0.3308, 0.7802]])\n",
            "tensor([[0.3002, 0.7669, 0.8898, 0.9107],\n",
            "        [0.0219, 0.6328, 0.9235, 0.2540],\n",
            "        [0.2259, 0.8689, 0.3308, 0.7802]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ],
      "source": [
        "seed = 135\n",
        "torch.manual_seed(seed=seed)\n",
        "\n",
        "random_tensor_3 = torch.rand(3,4)\n",
        "\n",
        "torch.manual_seed(seed=seed)\n",
        "random_tensor_4 = torch.rand(3,4)\n",
        "\n",
        "print(random_tensor_3)\n",
        "print(random_tensor_4)\n",
        "print(random_tensor_3 == random_tensor_4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33PFYRAaI9XO"
      },
      "source": [
        "## **Running Tensors on GPU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INZBW3w9JBD9"
      },
      "source": [
        "Deep Learning requires a lot of computational and numerical operations, and they are done by default on CPU, however, we can do them on GPUs as well. It will generally speed things up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHyX8fINJQiV"
      },
      "source": [
        "We will be focusing on NVIDIA GPU in this one, for Apple Sillicon, I will maybe write another one. We can check the GPU by running `|!nvidia-smi`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFoVh19VI1yo",
        "outputId": "934b6e3d-948c-4f46-d146-755c199a9415"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Jul 10 19:06:33 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 565.57.01              Driver Version: 566.24         CUDA Version: 12.7     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3070        On  |   00000000:01:00.0  On |                  N/A |\n",
            "| 30%   47C    P8             21W /  220W |    7799MiB /   8192MiB |     20%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A       499      G   /Xwayland                                   N/A      |\n",
            "|    0   N/A  N/A      4897      C   /python3.11                                 N/A      |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znAmh_XSJf_u"
      },
      "source": [
        "### **Getting PyTorch to run GPU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUTo76PwJivd"
      },
      "source": [
        "Once you have the GPU access, the next step is to get PyTorch to store data and compute data on GPU. We use `torch.cuda` for this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXkc_DQDJiFW",
        "outputId": "c620cfac-74c3-409e-aaec-d79715866be8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcxzXq3yJvqm"
      },
      "source": [
        "or can use this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4tWCUywhJw1E",
        "outputId": "f0e2afb5-8e44-4a00-d2ef-bc6a6ca26f74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs_u1qNuJzet"
      },
      "source": [
        "This will run for everyone, if they don't have GPU, it will run on CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aN8kHGqJ64z"
      },
      "source": [
        "You can make use of multiple GPUs as well, if you have them available:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKlcJVfXJ3-E",
        "outputId": "00cc81db-e1b5-40b4-8a71-31e2e05e62b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# count the number of GPUs\n",
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQeDXWlnKEIz"
      },
      "source": [
        "### **Apple Silicon**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-wHRmE8KHSK"
      },
      "source": [
        "We have Apple's M1/M2/M3 and now M4 GPUs, and can run them using `torch.backends.mps`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F18OgGjgKGhT",
        "outputId": "1aacc882-f59e-41d5-a3b2-a3d80a60d640"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.backends.mps.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FiiOiEcqKUPs",
        "outputId": "afe6d169-18de-4fcd-f2f8-98053bdc1a26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "476LXYOCKV1T",
        "outputId": "f63cd096-81ee-4b20-a1be-4b6d2550ec7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8Kao8nGKiYr"
      },
      "source": [
        "### **Putting tensors and models on GPU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSvR3Lv8KmFz"
      },
      "source": [
        "We can put tensors and models on a specific device by calling `to(device)` on them. The reason to do this is GPUs offer far faster numerical computations than CPUs.\n",
        "\n",
        "Let's try it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz1M8gsqKe7D",
        "outputId": "6cedf202-9742-4d1c-c31c-b1390e1d3d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 4]) cpu\n",
            "tensor([1, 2, 4], device='cuda:0') cuda:0\n"
          ]
        }
      ],
      "source": [
        "tensor_A = torch.tensor([1,2,4])\n",
        "\n",
        "# not on GPU\n",
        "print(tensor_A, tensor_A.device)\n",
        "\n",
        "# move tensor to GPU (if available)\n",
        "tensor_B = tensor_A.to(device)\n",
        "print(tensor_B, tensor_B.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcVUJeXJMBix"
      },
      "source": [
        "### **Moving them back to CPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjgerq9jMToN",
        "outputId": "b910a25c-f065-480c-ffb7-65fa3247f367"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor on GPU: tensor([1, 2, 4], device='cuda:0') and the device is:  cuda:0\n",
            "Tensor on CPU: [1 2 4] and the device is:  cpu\n"
          ]
        }
      ],
      "source": [
        "tensor_C = tensor_B.cpu().numpy()\n",
        "print(f\"Tensor on GPU: {tensor_B} and the device is:  {tensor_B.device}\")\n",
        "print(f\"Tensor on CPU: {tensor_C} and the device is:  {tensor_C.device}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uQ9q6lCHp9_i",
        "xvwpZZgsq2Yd",
        "fypQA0mXreU0",
        "mAJTArXQsALb",
        "4q4Ttuynsopr",
        "QWBYkaRetdZT",
        "eC0ISSlSuIWE",
        "YZL3o5VBuhLC",
        "z4ApRfz23xXM"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
