{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a9a731e",
   "metadata": {},
   "source": [
    "## **JAX**\n",
    "\n",
    "JAX is a library for array-oriented numerical computation, with automatic differentiation and JIT compilation to enable high-performance machine learning research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3c65fe",
   "metadata": {},
   "source": [
    "1. JAX provide a unified NumPy-like interface to computations that run on CPU, GPU or TPI, in local or distributed settings,\n",
    "2. JAX features built-in Jut-in-Time (JIT) compilation, and open source machine learning compiler ecosystem.\n",
    "3. JAX functions support efficient evalution of gradients via its automatic differentiation transformations.\n",
    "4. JAX functions can be automatically vectorized to efficiently map them over arrays representing batches of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7128679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e969f0c",
   "metadata": {},
   "source": [
    "With the above import, we can immediately start using JAX in a similar manner to NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e6e1252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        1.05      2.1       3.1499999 4.2      ]\n"
     ]
    }
   ],
   "source": [
    "def selu(x, alpha=1.67, lmbda=1.05):\n",
    "  return lmbda * jnp.where(x > 0, x, alpha * jnp.exp(x) - alpha)\n",
    "\n",
    "x = jnp.arange(5.0)\n",
    "print(selu(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189d1e4e",
   "metadata": {},
   "source": [
    "JAX works great for many numerical and scientific programs, but only if they are written with certain constraints, as explained in [tutorial_n.ipynb](#add_link_when_done)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6837fd",
   "metadata": {},
   "source": [
    "### **Just-in-time compilation with `jax.jit()`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843d0535",
   "metadata": {},
   "source": [
    "JAX runs transparently on the GPU or TPU (falling back to CPU if you don't have one). However, in the above code, JAX is dispatching kernels to the chip one operation at a time. If we have a sequence of operations, we can use the `jax.jit()` function to compile this sequence of operations together using XLA.\n",
    "\n",
    "\n",
    "We can use python's `%timeit` to quickly benchmark our `selu` function, using `block_until_ready()` to account for JAX's dynamic dispatch. See [tutorial_async](#add_it_too) for more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e14fb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845 μs ± 32.5 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "from jax import random\n",
    "\n",
    "key = random.key(135)\n",
    "x = random.normal(key, (1_000_000,))\n",
    "%timeit selu(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb81ffca",
   "metadata": {},
   "source": [
    "We can speed the execution time for this function with `jax.jit()` transformation, which will `jit-compile` the first time `selu` is called and it will be cached forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2420486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342 μs ± 32.9 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "from jax import jit\n",
    "\n",
    "selu_jit = jit(selu)\n",
    "_ = selu_jit(x)  # warmup\n",
    "%timeit selu_jit(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50deb012",
   "metadata": {},
   "source": [
    "This is just the execution time on CPU, the same code can be run on GPU, or TPU, typically for even greater speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478db392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
